{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"733-fjnKvJ4I","executionInfo":{"status":"ok","timestamp":1658950506507,"user_tz":-60,"elapsed":20673,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"83e193db-2429-47fe-9e1b-aab473799248"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["%cd /content/gdrive/My Drive/TensorFlow/models/research/\n","!protoc object_detection/protos/*.proto --python_out=.\n","# Install TensorFlow Object Detection API.\n","!cp object_detection/packages/tf2/setup.py .\n","!python -m pip install . --use-feature=in-tree-build"],"metadata":{"id":"WRLJm-qismCv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658950996053,"user_tz":-60,"elapsed":489554,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"0bd83867-af38-4e78-afb7-83cb71852e5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/TensorFlow/models/research\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/gdrive/MyDrive/TensorFlow/models/research\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.40.0-cp37-cp37m-manylinux2010_x86_64.whl (10.9 MB)\n","\u001b[K     |████████████████████████████████| 10.9 MB 24.0 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.30)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 59.2 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 59.5 MB/s \n","\u001b[?25hCollecting tensorflow_io\n","  Downloading tensorflow_io-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n","\u001b[K     |████████████████████████████████| 25.9 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n","Collecting pyparsing==2.4.7\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 10.3 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 51.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 56.1 MB/s \n","\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n","\u001b[K     |████████████████████████████████| 238 kB 67.6 MB/s \n","\u001b[?25hCollecting sacrebleu\n","  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n","\u001b[K     |████████████████████████████████| 116 kB 52.8 MB/s \n","\u001b[?25hCollecting tensorflow~=2.9.0\n","  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","\u001b[K     |████████████████████████████████| 511.7 MB 5.7 kB/s \n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n","\u001b[?25hCollecting opencv-python-headless\n","  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n","\u001b[K     |████████████████████████████████| 48.3 MB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Collecting tensorflow-text~=2.9.0\n","  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[K     |████████████████████████████████| 4.6 MB 46.9 MB/s \n","\u001b[?25hCollecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 75.1 MB/s \n","\u001b[?25hRequirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n","Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.15)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n","  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n","\u001b[K     |████████████████████████████████| 438 kB 73.4 MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n","Collecting flatbuffers<2,>=1.12\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Collecting tensorboard<2.10,>=2.9\n","  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 48.5 MB/s \n","\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Collecting gast<=0.4.0,>=0.2.1\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.26.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.47.0)\n","Collecting keras\n","  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 54.8 MB/s \n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n","Collecting orjson<4.0\n","  Downloading orjson-3.7.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n","\u001b[K     |████████████████████████████████| 272 kB 74.1 MB/s \n","\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting fastavro<2,>=0.23.6\n","  Downloading fastavro-1.5.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 52.8 MB/s \n","\u001b[?25hCollecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.20.6-py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n","\u001b[?25hCollecting cloudpickle<3,>=2.1.0\n","  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 73.2 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n","Collecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","\u001b[K     |████████████████████████████████| 508 kB 70.5 MB/s \n","\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Collecting protobuf<4.0.0dev,>=3.12.0\n","  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 45.4 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Collecting portalocker\n","  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.10)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.9.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.9.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n","Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=21937616 sha256=18cc0e7750a259cd6649f01636a7c2e1c23bf5079d2d68169fe2dd164c2d1233\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-n8u0frfo/wheels/97/53/2e/d48d2cde7a3215930042ae98dd70ce3a4a25072bde25839867\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=de805f2999d9d1ee602a4925e22628510636948a562db47a0a94c89180259cd6\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=1f32b65a56d9de1cc4254ac18ba4b2c67d8ddedca4ceb8a2663994e51f981178\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=c1402511d8a96458c575525cebb8de524ee070127e4595ac6632d99ef2fe9542\n","  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=dcdb2d396c61920b8ecf8b1c0f7576f0e649fdc4aab2b1984e899c81aedb59bc\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n","Installing collected packages: requests, pyparsing, protobuf, tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.0.9\n","    Uninstalling pyparsing-3.0.9:\n","      Successfully uninstalled pyparsing-3.0.9\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.8.0\n","    Uninstalling tensorboard-2.8.0:\n","      Successfully uninstalled tensorboard-2.8.0\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.8.0\n","    Uninstalling keras-2.8.0:\n","      Successfully uninstalled keras-2.8.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 2.0\n","    Uninstalling flatbuffers-2.0:\n","      Successfully uninstalled flatbuffers-2.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n","    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n","      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.5.1\n","    Uninstalling dill-0.3.5.1:\n","      Successfully uninstalled dill-0.3.5.1\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.2.0\n","    Uninstalling pymongo-4.2.0:\n","      Successfully uninstalled pymongo-4.2.0\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.13 requires dill>=0.3.5.1, but you have dill 0.3.1.1 which is incompatible.\n","gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed apache-beam-2.40.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.5 dill-0.3.1.1 fastavro-1.5.3 flatbuffers-1.12 gast-0.4.0 hdfs-2.7.0 keras-2.9.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.6.0.66 orjson-3.7.8 portalocker-2.5.1 proto-plus-1.20.6 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.2.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-addons-0.17.1 tensorflow-estimator-2.9.0 tensorflow-io-0.26.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.9.0 tf-models-official-2.9.2 tf-slim-1.1.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4luXQGcOXynB"},"outputs":[],"source":["from object_detection.utils import ops as utils_ops\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util"]},{"cell_type":"code","source":["!python /content/gdrive/MyDrive/TensorFlow/models/research/object_detection/builders/model_builder_tf2_test.py"],"metadata":{"id":"A-xqgBYAsvSc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658951044412,"user_tz":-60,"elapsed":40481,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"49c41fb0-8e32-4f85-8224-b9871286d138"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running tests under Python 3.7.13: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2022-07-27 19:43:30.994205: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","W0727 19:43:32.291660 139766518028160 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 4.02s\n","I0727 19:43:32.903119 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 4.02s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.18s\n","I0727 19:43:34.082760 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.18s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.55s\n","I0727 19:43:34.630601 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.55s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.49s\n","I0727 19:43:35.116367 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.49s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 3.36s\n","I0727 19:43:38.474222 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 3.36s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0727 19:43:38.475479 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.05s\n","I0727 19:43:38.525631 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.05s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.07s\n","I0727 19:43:38.596755 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.07s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.04s\n","I0727 19:43:38.634795 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.04s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.24s\n","I0727 19:43:38.878822 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.24s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.19s\n","I0727 19:43:39.072520 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.19s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.2s\n","I0727 19:43:39.273989 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.2s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.17s\n","I0727 19:43:39.440505 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.17s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.21s\n","I0727 19:43:39.647451 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.21s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.06s\n","I0727 19:43:39.709504 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.06s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0727 19:43:40.090276 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0727 19:43:40.090527 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0727 19:43:40.090631 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0727 19:43:40.094253 139766518028160 efficientnet_model.py:143] round_filter input=32 output=32\n","I0727 19:43:40.126080 139766518028160 efficientnet_model.py:143] round_filter input=32 output=32\n","I0727 19:43:40.126225 139766518028160 efficientnet_model.py:143] round_filter input=16 output=16\n","I0727 19:43:40.224964 139766518028160 efficientnet_model.py:143] round_filter input=16 output=16\n","I0727 19:43:40.225157 139766518028160 efficientnet_model.py:143] round_filter input=24 output=24\n","I0727 19:43:40.877376 139766518028160 efficientnet_model.py:143] round_filter input=24 output=24\n","I0727 19:43:40.877608 139766518028160 efficientnet_model.py:143] round_filter input=40 output=40\n","I0727 19:43:41.192936 139766518028160 efficientnet_model.py:143] round_filter input=40 output=40\n","I0727 19:43:41.193134 139766518028160 efficientnet_model.py:143] round_filter input=80 output=80\n","I0727 19:43:41.565654 139766518028160 efficientnet_model.py:143] round_filter input=80 output=80\n","I0727 19:43:41.565841 139766518028160 efficientnet_model.py:143] round_filter input=112 output=112\n","I0727 19:43:41.949791 139766518028160 efficientnet_model.py:143] round_filter input=112 output=112\n","I0727 19:43:41.949967 139766518028160 efficientnet_model.py:143] round_filter input=192 output=192\n","I0727 19:43:42.264116 139766518028160 efficientnet_model.py:143] round_filter input=192 output=192\n","I0727 19:43:42.264290 139766518028160 efficientnet_model.py:143] round_filter input=320 output=320\n","I0727 19:43:42.337458 139766518028160 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I0727 19:43:42.367927 139766518028160 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0727 19:43:42.419425 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0727 19:43:42.419575 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n","I0727 19:43:42.419650 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n","I0727 19:43:42.421163 139766518028160 efficientnet_model.py:143] round_filter input=32 output=32\n","I0727 19:43:42.436445 139766518028160 efficientnet_model.py:143] round_filter input=32 output=32\n","I0727 19:43:42.436552 139766518028160 efficientnet_model.py:143] round_filter input=16 output=16\n","I0727 19:43:42.557549 139766518028160 efficientnet_model.py:143] round_filter input=16 output=16\n","I0727 19:43:42.557694 139766518028160 efficientnet_model.py:143] round_filter input=24 output=24\n","I0727 19:43:42.789329 139766518028160 efficientnet_model.py:143] round_filter input=24 output=24\n","I0727 19:43:42.789509 139766518028160 efficientnet_model.py:143] round_filter input=40 output=40\n","I0727 19:43:43.021674 139766518028160 efficientnet_model.py:143] round_filter input=40 output=40\n","I0727 19:43:43.021858 139766518028160 efficientnet_model.py:143] round_filter input=80 output=80\n","I0727 19:43:43.329994 139766518028160 efficientnet_model.py:143] round_filter input=80 output=80\n","I0727 19:43:43.330161 139766518028160 efficientnet_model.py:143] round_filter input=112 output=112\n","I0727 19:43:43.634865 139766518028160 efficientnet_model.py:143] round_filter input=112 output=112\n","I0727 19:43:43.635046 139766518028160 efficientnet_model.py:143] round_filter input=192 output=192\n","I0727 19:43:44.020563 139766518028160 efficientnet_model.py:143] round_filter input=192 output=192\n","I0727 19:43:44.020733 139766518028160 efficientnet_model.py:143] round_filter input=320 output=320\n","I0727 19:43:44.169548 139766518028160 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I0727 19:43:44.199789 139766518028160 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0727 19:43:44.269840 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0727 19:43:44.270003 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n","I0727 19:43:44.270072 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n","I0727 19:43:44.271652 139766518028160 efficientnet_model.py:143] round_filter input=32 output=32\n","I0727 19:43:44.286939 139766518028160 efficientnet_model.py:143] round_filter input=32 output=32\n","I0727 19:43:44.287044 139766518028160 efficientnet_model.py:143] round_filter input=16 output=16\n","I0727 19:43:44.403733 139766518028160 efficientnet_model.py:143] round_filter input=16 output=16\n","I0727 19:43:44.403882 139766518028160 efficientnet_model.py:143] round_filter input=24 output=24\n","I0727 19:43:44.630651 139766518028160 efficientnet_model.py:143] round_filter input=24 output=24\n","I0727 19:43:44.630818 139766518028160 efficientnet_model.py:143] round_filter input=40 output=48\n","I0727 19:43:44.852929 139766518028160 efficientnet_model.py:143] round_filter input=40 output=48\n","I0727 19:43:44.853127 139766518028160 efficientnet_model.py:143] round_filter input=80 output=88\n","I0727 19:43:45.163511 139766518028160 efficientnet_model.py:143] round_filter input=80 output=88\n","I0727 19:43:45.163676 139766518028160 efficientnet_model.py:143] round_filter input=112 output=120\n","I0727 19:43:45.493621 139766518028160 efficientnet_model.py:143] round_filter input=112 output=120\n","I0727 19:43:45.493804 139766518028160 efficientnet_model.py:143] round_filter input=192 output=208\n","I0727 19:43:45.883453 139766518028160 efficientnet_model.py:143] round_filter input=192 output=208\n","I0727 19:43:45.883624 139766518028160 efficientnet_model.py:143] round_filter input=320 output=352\n","I0727 19:43:46.037058 139766518028160 efficientnet_model.py:143] round_filter input=1280 output=1408\n","I0727 19:43:46.066619 139766518028160 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0727 19:43:46.127084 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0727 19:43:46.127258 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n","I0727 19:43:46.127332 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n","I0727 19:43:46.128848 139766518028160 efficientnet_model.py:143] round_filter input=32 output=40\n","I0727 19:43:46.144559 139766518028160 efficientnet_model.py:143] round_filter input=32 output=40\n","I0727 19:43:46.144671 139766518028160 efficientnet_model.py:143] round_filter input=16 output=24\n","I0727 19:43:46.277986 139766518028160 efficientnet_model.py:143] round_filter input=16 output=24\n","I0727 19:43:46.278157 139766518028160 efficientnet_model.py:143] round_filter input=24 output=32\n","I0727 19:43:46.701995 139766518028160 efficientnet_model.py:143] round_filter input=24 output=32\n","I0727 19:43:46.702183 139766518028160 efficientnet_model.py:143] round_filter input=40 output=48\n","I0727 19:43:46.929670 139766518028160 efficientnet_model.py:143] round_filter input=40 output=48\n","I0727 19:43:46.929846 139766518028160 efficientnet_model.py:143] round_filter input=80 output=96\n","I0727 19:43:47.322839 139766518028160 efficientnet_model.py:143] round_filter input=80 output=96\n","I0727 19:43:47.323013 139766518028160 efficientnet_model.py:143] round_filter input=112 output=136\n","I0727 19:43:47.771016 139766518028160 efficientnet_model.py:143] round_filter input=112 output=136\n","I0727 19:43:47.771186 139766518028160 efficientnet_model.py:143] round_filter input=192 output=232\n","I0727 19:43:48.229832 139766518028160 efficientnet_model.py:143] round_filter input=192 output=232\n","I0727 19:43:48.230008 139766518028160 efficientnet_model.py:143] round_filter input=320 output=384\n","I0727 19:43:48.384317 139766518028160 efficientnet_model.py:143] round_filter input=1280 output=1536\n","I0727 19:43:48.412331 139766518028160 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0727 19:43:48.477464 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0727 19:43:48.477621 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n","I0727 19:43:48.477688 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0727 19:43:48.479227 139766518028160 efficientnet_model.py:143] round_filter input=32 output=48\n","I0727 19:43:48.495105 139766518028160 efficientnet_model.py:143] round_filter input=32 output=48\n","I0727 19:43:48.495213 139766518028160 efficientnet_model.py:143] round_filter input=16 output=24\n","I0727 19:43:48.612122 139766518028160 efficientnet_model.py:143] round_filter input=16 output=24\n","I0727 19:43:48.612277 139766518028160 efficientnet_model.py:143] round_filter input=24 output=32\n","I0727 19:43:48.916086 139766518028160 efficientnet_model.py:143] round_filter input=24 output=32\n","I0727 19:43:48.916257 139766518028160 efficientnet_model.py:143] round_filter input=40 output=56\n","I0727 19:43:49.224916 139766518028160 efficientnet_model.py:143] round_filter input=40 output=56\n","I0727 19:43:49.225083 139766518028160 efficientnet_model.py:143] round_filter input=80 output=112\n","I0727 19:43:49.691591 139766518028160 efficientnet_model.py:143] round_filter input=80 output=112\n","I0727 19:43:49.691807 139766518028160 efficientnet_model.py:143] round_filter input=112 output=160\n","I0727 19:43:50.157616 139766518028160 efficientnet_model.py:143] round_filter input=112 output=160\n","I0727 19:43:50.157792 139766518028160 efficientnet_model.py:143] round_filter input=192 output=272\n","I0727 19:43:50.784198 139766518028160 efficientnet_model.py:143] round_filter input=192 output=272\n","I0727 19:43:50.784381 139766518028160 efficientnet_model.py:143] round_filter input=320 output=448\n","I0727 19:43:50.934538 139766518028160 efficientnet_model.py:143] round_filter input=1280 output=1792\n","I0727 19:43:50.963152 139766518028160 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0727 19:43:51.034814 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0727 19:43:51.034972 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n","I0727 19:43:51.035049 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0727 19:43:51.036538 139766518028160 efficientnet_model.py:143] round_filter input=32 output=48\n","I0727 19:43:51.051630 139766518028160 efficientnet_model.py:143] round_filter input=32 output=48\n","I0727 19:43:51.051740 139766518028160 efficientnet_model.py:143] round_filter input=16 output=24\n","I0727 19:43:51.235051 139766518028160 efficientnet_model.py:143] round_filter input=16 output=24\n","I0727 19:43:51.235209 139766518028160 efficientnet_model.py:143] round_filter input=24 output=40\n","I0727 19:43:51.625336 139766518028160 efficientnet_model.py:143] round_filter input=24 output=40\n","I0727 19:43:51.625523 139766518028160 efficientnet_model.py:143] round_filter input=40 output=64\n","I0727 19:43:52.230966 139766518028160 efficientnet_model.py:143] round_filter input=40 output=64\n","I0727 19:43:52.231142 139766518028160 efficientnet_model.py:143] round_filter input=80 output=128\n","I0727 19:43:52.770750 139766518028160 efficientnet_model.py:143] round_filter input=80 output=128\n","I0727 19:43:52.770928 139766518028160 efficientnet_model.py:143] round_filter input=112 output=176\n","I0727 19:43:53.305736 139766518028160 efficientnet_model.py:143] round_filter input=112 output=176\n","I0727 19:43:53.305901 139766518028160 efficientnet_model.py:143] round_filter input=192 output=304\n","I0727 19:43:53.994848 139766518028160 efficientnet_model.py:143] round_filter input=192 output=304\n","I0727 19:43:53.995026 139766518028160 efficientnet_model.py:143] round_filter input=320 output=512\n","I0727 19:43:54.223589 139766518028160 efficientnet_model.py:143] round_filter input=1280 output=2048\n","I0727 19:43:54.251709 139766518028160 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0727 19:43:54.337306 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0727 19:43:54.337482 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0727 19:43:54.337557 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0727 19:43:54.339092 139766518028160 efficientnet_model.py:143] round_filter input=32 output=56\n","I0727 19:43:54.355945 139766518028160 efficientnet_model.py:143] round_filter input=32 output=56\n","I0727 19:43:54.356065 139766518028160 efficientnet_model.py:143] round_filter input=16 output=32\n","I0727 19:43:54.545820 139766518028160 efficientnet_model.py:143] round_filter input=16 output=32\n","I0727 19:43:54.545986 139766518028160 efficientnet_model.py:143] round_filter input=24 output=40\n","I0727 19:43:55.008545 139766518028160 efficientnet_model.py:143] round_filter input=24 output=40\n","I0727 19:43:55.008716 139766518028160 efficientnet_model.py:143] round_filter input=40 output=72\n","I0727 19:43:55.466302 139766518028160 efficientnet_model.py:143] round_filter input=40 output=72\n","I0727 19:43:55.466478 139766518028160 efficientnet_model.py:143] round_filter input=80 output=144\n","I0727 19:43:56.090576 139766518028160 efficientnet_model.py:143] round_filter input=80 output=144\n","I0727 19:43:56.090748 139766518028160 efficientnet_model.py:143] round_filter input=112 output=200\n","I0727 19:43:56.706485 139766518028160 efficientnet_model.py:143] round_filter input=112 output=200\n","I0727 19:43:56.706658 139766518028160 efficientnet_model.py:143] round_filter input=192 output=344\n","I0727 19:43:57.578035 139766518028160 efficientnet_model.py:143] round_filter input=192 output=344\n","I0727 19:43:57.578232 139766518028160 efficientnet_model.py:143] round_filter input=320 output=576\n","I0727 19:43:57.808831 139766518028160 efficientnet_model.py:143] round_filter input=1280 output=2304\n","I0727 19:43:57.837701 139766518028160 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0727 19:43:58.157548 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0727 19:43:58.157713 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0727 19:43:58.157788 139766518028160 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0727 19:43:58.159302 139766518028160 efficientnet_model.py:143] round_filter input=32 output=64\n","I0727 19:43:58.174986 139766518028160 efficientnet_model.py:143] round_filter input=32 output=64\n","I0727 19:43:58.175095 139766518028160 efficientnet_model.py:143] round_filter input=16 output=32\n","I0727 19:43:58.426955 139766518028160 efficientnet_model.py:143] round_filter input=16 output=32\n","I0727 19:43:58.427177 139766518028160 efficientnet_model.py:143] round_filter input=24 output=48\n","I0727 19:43:58.976488 139766518028160 efficientnet_model.py:143] round_filter input=24 output=48\n","I0727 19:43:58.976663 139766518028160 efficientnet_model.py:143] round_filter input=40 output=80\n","I0727 19:43:59.530314 139766518028160 efficientnet_model.py:143] round_filter input=40 output=80\n","I0727 19:43:59.530511 139766518028160 efficientnet_model.py:143] round_filter input=80 output=160\n","I0727 19:44:00.310701 139766518028160 efficientnet_model.py:143] round_filter input=80 output=160\n","I0727 19:44:00.310882 139766518028160 efficientnet_model.py:143] round_filter input=112 output=224\n","I0727 19:44:01.080861 139766518028160 efficientnet_model.py:143] round_filter input=112 output=224\n","I0727 19:44:01.081039 139766518028160 efficientnet_model.py:143] round_filter input=192 output=384\n","I0727 19:44:02.087994 139766518028160 efficientnet_model.py:143] round_filter input=192 output=384\n","I0727 19:44:02.088171 139766518028160 efficientnet_model.py:143] round_filter input=320 output=640\n","I0727 19:44:02.396338 139766518028160 efficientnet_model.py:143] round_filter input=1280 output=2560\n","I0727 19:44:02.425150 139766518028160 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.83s\n","I0727 19:44:02.542266 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.83s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0727 19:44:02.550030 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0727 19:44:02.552094 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0727 19:44:02.552613 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0727 19:44:02.554227 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0727 19:44:02.555549 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0727 19:44:02.555956 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0727 19:44:02.556883 139766518028160 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 33.676s\n","\n","OK (skipped=1)\n"]}]},{"cell_type":"markdown","metadata":{"id":"vQ9iPmLFEQJi"},"source":["NOTE:\n","\n","You should have the images in test and train folder (with their corresponding XML files) and label_map.pbtxt file ready in respective directories.\n","\n","You should also have the generate_tfrecord.py in your preprocessing directory.\n","\n","If you don't have these files ready, go back to Step 1 and finish downloading required files."]},{"cell_type":"markdown","source":["Not neccessary to reload it everytime if not for random state\n","at least take 20 mins \n","will take will long time to load the image in the drive"],"metadata":{"id":"hDpyBhJGEbIE"}},{"cell_type":"code","source":["#%cd '/content/gdrive/MyDrive/TensorFlow/scripts/preprocessing'\n","#!python partition_dataset.py -i '/content/gdrive/MyDrive/TensorFlow/workspace/model3/images/Legal_DataAUGed/' -o '/content/gdrive/MyDrive/TensorFlow/workspace/model3/images/' -x --xml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bRNKeP5p_sOU","executionInfo":{"status":"ok","timestamp":1658434885375,"user_tz":-60,"elapsed":3345,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"af96b94f-0d78-45b0-d547-679e50ac8022"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/TensorFlow/scripts/preprocessing\n","partition_dataset.py:35: DeprecationWarning: Flags not at the start of the expression '([a-zA-Z0-9\\\\s_\\\\\\\\.\\\\-\\\\' (truncated)\n","  if re.search(r'([a-zA-Z0-9\\s_\\\\.\\-\\(\\):])+(?i)(.jpg|.jpeg|.png)$', f)]\n"]}]},{"cell_type":"code","source":["#%cd '/content/gdrive/MyDrive/TensorFlow/scripts/preprocessing'\n","#!python partition_dataset.py -i '/content/gdrive/MyDrive/TensorFlow/workspace/model3/images/Illegal_DataAUGed/' -o '/content/gdrive/MyDrive/TensorFlow/workspace/model3/images/' -x --xml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u6zTj1gCZbfC","executionInfo":{"status":"ok","timestamp":1658435012900,"user_tz":-60,"elapsed":11622,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"451f7a86-1220-4235-8e8a-9801ea464e24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/TensorFlow/scripts/preprocessing\n","partition_dataset.py:35: DeprecationWarning: Flags not at the start of the expression '([a-zA-Z0-9\\\\s_\\\\\\\\.\\\\-\\\\' (truncated)\n","  if re.search(r'([a-zA-Z0-9\\s_\\\\.\\-\\(\\):])+(?i)(.jpg|.jpeg|.png)$', f)]\n"]}]},{"cell_type":"markdown","source":["making CSV for record and tell the annination \n"],"metadata":{"id":"kv1IfmTNEhOS"}},{"cell_type":"code","source":["%cd '/content/gdrive/My Drive/TensorFlow/workspace/model3'\n","!python xml_to_csv.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U1hXHpgTC1xu","executionInfo":{"status":"ok","timestamp":1658951078388,"user_tz":-60,"elapsed":33981,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"dcae983c-4e7b-425e-8c28-8c7adda43933"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/TensorFlow/workspace/model3\n","Successfully converted xml to csv.\n","Successfully converted xml to csv.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14989,"status":"ok","timestamp":1658951207222,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"},"user_tz":-60},"id":"h5C5-PCp-elV","outputId":"d950d63e-aadf-484d-f694-06e71bad9d71"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/TensorFlow/scripts/preprocessing\n","Successfully created the TFRecord file: /content/gdrive/My Drive/TensorFlow/workspace/model3/annotations/train.record\n","Successfully created the CSV file: /content/gdrive/My Drive/TensorFlow/workspace/model3/images/train.record\n","Successfully created the TFRecord file: /content/gdrive/My Drive/TensorFlow/workspace/model3/annotations/test.record\n","Successfully created the CSV file: /content/gdrive/My Drive/TensorFlow/workspace/model3/images/test.record\n"]}],"source":["#Step 11- Generate TFrecords.\n","#cd into preprocessing directory\n","%cd '/content/gdrive/My Drive/TensorFlow/scripts/preprocessing'\n","\n","#run the cell to generate test.record and train.record\n","!python generate_tfrecord.py -x '/content/gdrive/My Drive/TensorFlow/workspace/model3/images/train' -l '/content/gdrive/My Drive/TensorFlow/workspace/model3/annotations/label_map.pbtxt' -o '/content/gdrive/My Drive/TensorFlow/workspace/model3/annotations/train.record' -c '/content/gdrive/My Drive/TensorFlow/workspace/model3/images/train.record'\n","!python generate_tfrecord.py -x '/content/gdrive/My Drive/TensorFlow/workspace/model3/images/test' -l '/content/gdrive/My Drive/TensorFlow/workspace/model3/annotations/label_map.pbtxt' -o '/content/gdrive/My Drive/TensorFlow/workspace/model3/annotations/test.record' -c '/content/gdrive/My Drive/TensorFlow/workspace/model3/images/test.record'\n","\n","# !python generate_tfrecord.py -x '[path_to_train_folder]' -l '[path_to_annotations_folder]/label_map.pbtxt' -o '[path_to_annotations_folder]/train.record' -c '[path_to_csv'\n","# !python generate_tfrecord.py -x '[path_to_test_folder]' -l '[path_to_annotations_folder]/label_map.pbtxt' -o '[path_to_annotations_folder]/test.record' -c '[path_to_csv'\n"]},{"cell_type":"code","source":["#copy them to config\n","!ls\n","num_classes = 2\n","batch_size = 4 #16\n","num_steps = 300000 #1500\n","num_eval_steps = 1000\n","\n","train_record_path = '/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/train.record'\n","test_record_path = '/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/test.record'\n","model_dir = '/content/gdrive/MyDrive/TensorFlow/workspace/model3/exported-models'\n","labelmap_path = '/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/label_map.pbtxt'\n","\n","pipeline_config_path = '/content/gdrive/MyDrive/TensorFlow/workspace/model3/models/my_fat_cnnresnet50/pipeline.config'\n","fine_tune_checkpoint = '/content/gdrive/MyDrive/TensorFlow/workspace/model3/models/my_fat_cnnresnet50/checkpoint/ckpt-0'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TCTJRiKOxQWN","executionInfo":{"status":"ok","timestamp":1658951219602,"user_tz":-60,"elapsed":448,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"0f0fc994-4632-437b-ebae-296112c8f31b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" augment_with_KPs.py   generate_tfrecord2.py   partition_dataset.py\n","'Data Aug.ipynb'       generate_tfrecord.py\n"]}]},{"cell_type":"code","source":["import re\n","\n","with open(pipeline_config_path) as f:\n","    config = f.read()\n","\n","with open(pipeline_config_path, 'w') as f:\n","\n","  # Set labelmap path\n","  config = re.sub('label_map_path: \".*?\"', \n","             'label_map_path: \"{}\"'.format(labelmap_path), config)\n","  \n","  # Set fine_tune_checkpoint path\n","  config = re.sub('fine_tune_checkpoint: \".*?\"',\n","                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n","  \n","   # Set train tf-record file path\n","  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n","                  'input_path: \"{}\"'.format(train_record_path), config)\n","  \n","  # Set test tf-record file path\n","  #config = re.sub('(input_path: \".*?)(/content/dataset/train.record)(.*?\")', \n","   #               'input_path: \"{}\"'.format(train_record_path), config)\n","  \n","  # Set train tf-record file path\n","  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n","                  'input_path: \"{}\"'.format(test_record_path), config)\n","  \n","  # Set test tf-record file path\n","  #config = re.sub('(input_path: \".*?)(/content/dataset/test.record)(.*?\")', \n","   #               'input_path: \"{}\"'.format(test_record_path), config)\n","  \n","  # Set number of classes.\n","  config = re.sub('num_classes: [0-9]+',\n","                  'num_classes: {}'.format(num_classes), config)\n","  \n","  # Set batch size\n","  config = re.sub('batch_size: [0-9]+',\n","                  'batch_size: {}'.format(batch_size), config)\n","  \n","  # Set training steps\n","  config = re.sub('num_steps: [0-9]+',\n","                  'num_steps: {}'.format(num_steps), config)\n","  \n","  f.write(config)\n","\n","  print(config)"],"metadata":{"id":"NR4n6Qx7z5-4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658951226688,"user_tz":-60,"elapsed":737,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"3ed18572-0960-4c65-adfd-07067e7ac310"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["# Faster R-CNN with Resnet-50 (v1)\n","# Trained on COCO, initialized from Imagenet classification checkpoint\n","\n","# Achieves -- mAP on COCO14 minival dataset.\n","\n","# This config is TPU compatible.\n","\n","model {\n","  faster_rcnn {\n","    num_classes: 2\n","    image_resizer {\n","      keep_aspect_ratio_resizer {\n","        min_dimension: 640\n","        max_dimension: 640\n","        pad_to_max_dimension: true\n","      }\n","    }\n","    feature_extractor {\n","      type: 'faster_rcnn_resnet50_keras'\n","      batch_norm_trainable: true\n","    }\n","    first_stage_anchor_generator {\n","      grid_anchor_generator {\n","        scales: [0.25, 0.5, 1.0, 2.0]\n","        aspect_ratios: [0.5, 1.0, 2.0]\n","        height_stride: 16\n","        width_stride: 16\n","      }\n","    }\n","    first_stage_box_predictor_conv_hyperparams {\n","      op: CONV\n","      regularizer {\n","        l2_regularizer {\n","          weight: 0.0\n","        }\n","      }\n","      initializer {\n","        truncated_normal_initializer {\n","          stddev: 0.01\n","        }\n","      }\n","    }\n","    first_stage_nms_score_threshold: 0.0\n","    first_stage_nms_iou_threshold: 0.7\n","    first_stage_max_proposals: 300\n","    first_stage_localization_loss_weight: 2.0\n","    first_stage_objectness_loss_weight: 1.0\n","    initial_crop_size: 14\n","    maxpool_kernel_size: 2\n","    maxpool_stride: 2\n","    second_stage_box_predictor {\n","      mask_rcnn_box_predictor {\n","        use_dropout: false\n","        dropout_keep_probability: 1.0\n","        fc_hyperparams {\n","          op: FC\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.0\n","            }\n","          }\n","          initializer {\n","            variance_scaling_initializer {\n","              factor: 1.0\n","              uniform: true\n","              mode: FAN_AVG\n","            }\n","          }\n","        }\n","        share_box_across_classes: true\n","      }\n","    }\n","    second_stage_post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.0\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 300\n","      }\n","      score_converter: SOFTMAX\n","    }\n","    second_stage_localization_loss_weight: 2.0\n","    second_stage_classification_loss_weight: 1.0\n","    use_static_shapes: true\n","    use_matmul_crop_and_resize: true\n","    clip_anchors_to_image: true\n","    use_static_balanced_label_sampler: true\n","    use_matmul_gather_in_matcher: true\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 4\n","  sync_replicas: true\n","  startup_delay_steps: 0\n","  replicas_to_aggregate: 8\n","  num_steps: 300000\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: .04\n","          total_steps: 25000\n","          warmup_learning_rate: .013333\n","          warmup_steps: 2000\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint: \"/content/gdrive/MyDrive/TensorFlow/workspace/model3/models/my_fat_cnnresnet50/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_type: \"detection\"\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  use_bfloat16: false  # works only on TPUs\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  batch_size: 4;\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/test.record\"\n","  }\n","}\n","\n"]}]},{"cell_type":"code","source":["#CUDA ISSUE FIXED\n","!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4svVP77sxato","executionInfo":{"status":"ok","timestamp":1658951289305,"user_tz":-60,"elapsed":55415,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"f7925599-2a20-4ff4-e22f-5b9e38b384ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following packages will be REMOVED:\n","  libcudnn8-dev\n","The following held packages will be changed:\n","  libcudnn8\n","The following packages will be upgraded:\n","  libcudnn8\n","1 upgraded, 0 newly installed, 1 to remove and 47 not upgraded.\n","Need to get 430 MB of archives.\n","After this operation, 3,139 MB disk space will be freed.\n","Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n","Fetched 430 MB in 7s (61.5 MB/s)\n","(Reading database ... 155653 files and directories currently installed.)\n","Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n","(Reading database ... 155631 files and directories currently installed.)\n","Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n","Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n","Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7JISAAfK-inS","colab":{"base_uri":"https://localhost:8080/","height":838},"executionInfo":{"status":"ok","timestamp":1658951305889,"user_tz":-60,"elapsed":5018,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"4f161a38-d3cb-40d0-d4a0-32c68b44024b"},"outputs":[],"source":["#Step 14- Start Tensorboard.\n","\n","#cd into model3\n","%cd '/content/gdrive/My Drive/TensorFlow/workspace/model3'\n","\n","#start the Tensorboard\n","%load_ext tensorboard\n","%tensorboard --logdir=exported-models/train\n","\n","# %load_ext tensorboard\n","# %tensorboard --logdir=models/[name_of_pre-trained-model_you_downloaded]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":410,"status":"ok","timestamp":1658951307497,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"},"user_tz":-60},"id":"e_hgJrWJuC_O","outputId":"83f9c303-2012-455f-95eb-5ced78d814db"},"outputs":[{"output_type":"stream","name":"stdout","text":["11.673889328903622\n"]}],"source":["#optional\n","#code to check how much session time is remaining \n","\n","import time,psutil\n","uptime=time.time()-psutil.boot_time()\n","remaintime=(12*60*60)-uptime\n","print(remaintime/(60*60))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yg6JsWnbO3wt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658951325350,"user_tz":-60,"elapsed":12114,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"0d67c42f-9eb2-4c75-b365-d2cda0228273"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: opencv-python-headless 4.6.0.66\n","Uninstalling opencv-python-headless-4.6.0.66:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/cv2/*\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.6.0.66.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-5896f664.so.58.134.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-8ef5c7db.so.58.76.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-9c768859.so.56.70.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-d21001fc.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libgfortran-91cc3cb1.so.3.0.0\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libopenblas-r0-f650aae0.3.3.so\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libpng16-57e5e0a0.so.16.37.0\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libquadmath-96973f99.so.0.0.0\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-c8c53640.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-99364a1c.so.3.9.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-e6451464.so.5.9.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-f22f1483.so.7.0.0\n","  Would not remove (might be manually added):\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSans-Bold.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSans-BoldOblique.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSans-ExtraLight.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSans-Oblique.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSans.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSansCondensed-Bold.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSansCondensed-BoldOblique.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSansCondensed-Oblique.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSansCondensed.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/plugins/platforms/libqxcb.so\n","Proceed (y/n)? y\n","  Successfully uninstalled opencv-python-headless-4.6.0.66\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting opencv-python-headless==4.1.2.30\n","  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n","\u001b[K     |████████████████████████████████| 21.8 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.6)\n","Installing collected packages: opencv-python-headless\n","Successfully installed opencv-python-headless-4.1.2.30\n"]}],"source":["!pip uninstall opencv-python-headless # IMPORTANT TO DOWNGRADE THIS\n","!pip install opencv-python-headless==4.1.2.30"]},{"cell_type":"code","source":["print(pipeline_config_path)\n","!python /content/gdrive/MyDrive/TensorFlow/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_config_path} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --sample_1_of_n_eval_examples=1 \\\n","    --num_eval_steps={num_eval_steps}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cAe3lxK975WV","outputId":"227b87ca-5f6f-4aa7-8c55-48b29c0cf768","executionInfo":{"status":"ok","timestamp":1658952797787,"user_tz":-60,"elapsed":1428829,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/TensorFlow/workspace/model3/models/my_fat_cnnresnet50/pipeline.config\n","2022-07-27 19:49:33.579326: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0727 19:49:33.586626 139909792601984 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 300000\n","I0727 19:49:33.592631 139909792601984 config_util.py:552] Maybe overwriting train_steps: 300000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0727 19:49:33.592803 139909792601984 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0727 19:49:33.623134 139909792601984 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/train.record']\n","I0727 19:49:33.632319 139909792601984 dataset_builder.py:162] Reading unweighted datasets: ['/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/train.record']\n","I0727 19:49:33.632713 139909792601984 dataset_builder.py:79] Reading record datasets for input file: ['/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0727 19:49:33.632822 139909792601984 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0727 19:49:33.632900 139909792601984 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0727 19:49:33.636068 139909792601984 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0727 19:49:33.654865 139909792601984 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0727 19:49:40.365816 139909792601984 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0727 19:49:43.119878 139909792601984 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0727 19:49:53.139068 139904981100288 convolutional_keras_box_predictor.py:153] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use ref() instead.\n","W0727 19:50:01.494013 139904981100288 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use ref() instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W0727 19:50:07.423256 139904981100288 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","2022-07-27 19:50:27.654275: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 18874368 exceeds 10% of free system memory.\n","2022-07-27 19:50:30.148681: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 18874368 exceeds 10% of free system memory.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0727 19:50:32.208608 139904913958656 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","2022-07-27 19:51:22.930422: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 18874368 exceeds 10% of free system memory.\n","2022-07-27 19:51:22.982971: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 18874368 exceeds 10% of free system memory.\n","2022-07-27 19:51:23.025236: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 18874368 exceeds 10% of free system memory.\n","INFO:tensorflow:Step 21100 per-step time 0.869s\n","I0727 19:51:58.722356 139909792601984 model_lib_v2.py:707] Step 21100 per-step time 0.869s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.01072514,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.016892925,\n"," 'Loss/RPNLoss/localization_loss': 0.008666886,\n"," 'Loss/RPNLoss/objectness_loss': 0.00086764374,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.037152596,\n"," 'learning_rate': 0.002771268}\n","I0727 19:51:58.722784 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.01072514,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.016892925,\n"," 'Loss/RPNLoss/localization_loss': 0.008666886,\n"," 'Loss/RPNLoss/objectness_loss': 0.00086764374,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.037152596,\n"," 'learning_rate': 0.002771268}\n","INFO:tensorflow:Step 21200 per-step time 0.303s\n","I0727 19:52:29.054694 139909792601984 model_lib_v2.py:707] Step 21200 per-step time 0.303s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0129508255,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.0090655405,\n"," 'Loss/RPNLoss/localization_loss': 0.0011284298,\n"," 'Loss/RPNLoss/objectness_loss': 0.00044582656,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.02359062,\n"," 'learning_rate': 0.002634139}\n","I0727 19:52:29.055016 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0129508255,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.0090655405,\n"," 'Loss/RPNLoss/localization_loss': 0.0011284298,\n"," 'Loss/RPNLoss/objectness_loss': 0.00044582656,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.02359062,\n"," 'learning_rate': 0.002634139}\n","INFO:tensorflow:Step 21300 per-step time 0.309s\n","I0727 19:52:59.955962 139909792601984 model_lib_v2.py:707] Step 21300 per-step time 0.309s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.026193779,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009202899,\n"," 'Loss/RPNLoss/localization_loss': 0.0014219347,\n"," 'Loss/RPNLoss/objectness_loss': 0.0012001197,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.038018737,\n"," 'learning_rate': 0.002500254}\n","I0727 19:52:59.956294 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.026193779,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009202899,\n"," 'Loss/RPNLoss/localization_loss': 0.0014219347,\n"," 'Loss/RPNLoss/objectness_loss': 0.0012001197,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.038018737,\n"," 'learning_rate': 0.002500254}\n","INFO:tensorflow:Step 21400 per-step time 0.302s\n","I0727 19:53:30.189927 139909792601984 model_lib_v2.py:707] Step 21400 per-step time 0.302s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.017177977,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.0088154655,\n"," 'Loss/RPNLoss/localization_loss': 0.0044579785,\n"," 'Loss/RPNLoss/objectness_loss': 0.00046619185,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.030917613,\n"," 'learning_rate': 0.002369629}\n","I0727 19:53:30.190324 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.017177977,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.0088154655,\n"," 'Loss/RPNLoss/localization_loss': 0.0044579785,\n"," 'Loss/RPNLoss/objectness_loss': 0.00046619185,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.030917613,\n"," 'learning_rate': 0.002369629}\n","INFO:tensorflow:Step 21500 per-step time 0.304s\n","I0727 19:54:00.570219 139909792601984 model_lib_v2.py:707] Step 21500 per-step time 0.304s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.026610618,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009750004,\n"," 'Loss/RPNLoss/localization_loss': 0.0021854953,\n"," 'Loss/RPNLoss/objectness_loss': 0.00033387638,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03887999,\n"," 'learning_rate': 0.0022422932}\n","I0727 19:54:00.570556 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.026610618,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009750004,\n"," 'Loss/RPNLoss/localization_loss': 0.0021854953,\n"," 'Loss/RPNLoss/objectness_loss': 0.00033387638,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03887999,\n"," 'learning_rate': 0.0022422932}\n","INFO:tensorflow:Step 21600 per-step time 0.312s\n","I0727 19:54:31.738549 139909792601984 model_lib_v2.py:707] Step 21600 per-step time 0.312s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.016392294,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.01596917,\n"," 'Loss/RPNLoss/localization_loss': 0.003953987,\n"," 'Loss/RPNLoss/objectness_loss': 0.002896725,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.039212175,\n"," 'learning_rate': 0.0021182739}\n","I0727 19:54:31.738872 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.016392294,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.01596917,\n"," 'Loss/RPNLoss/localization_loss': 0.003953987,\n"," 'Loss/RPNLoss/objectness_loss': 0.002896725,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.039212175,\n"," 'learning_rate': 0.0021182739}\n","INFO:tensorflow:Step 21700 per-step time 0.305s\n","I0727 19:55:02.230541 139909792601984 model_lib_v2.py:707] Step 21700 per-step time 0.305s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.024789464,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.008975131,\n"," 'Loss/RPNLoss/localization_loss': 0.0035416265,\n"," 'Loss/RPNLoss/objectness_loss': 0.00052188965,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03782811,\n"," 'learning_rate': 0.0019975877}\n","I0727 19:55:02.230872 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.024789464,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.008975131,\n"," 'Loss/RPNLoss/localization_loss': 0.0035416265,\n"," 'Loss/RPNLoss/objectness_loss': 0.00052188965,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03782811,\n"," 'learning_rate': 0.0019975877}\n","INFO:tensorflow:Step 21800 per-step time 0.305s\n","I0727 19:55:32.715781 139909792601984 model_lib_v2.py:707] Step 21800 per-step time 0.305s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.019517578,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009997758,\n"," 'Loss/RPNLoss/localization_loss': 0.0016760849,\n"," 'Loss/RPNLoss/objectness_loss': 0.0004257288,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03161715,\n"," 'learning_rate': 0.0018802618}\n","I0727 19:55:32.716111 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.019517578,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009997758,\n"," 'Loss/RPNLoss/localization_loss': 0.0016760849,\n"," 'Loss/RPNLoss/objectness_loss': 0.0004257288,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03161715,\n"," 'learning_rate': 0.0018802618}\n","INFO:tensorflow:Step 21900 per-step time 0.305s\n","I0727 19:56:03.167818 139909792601984 model_lib_v2.py:707] Step 21900 per-step time 0.305s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.017866006,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.016003102,\n"," 'Loss/RPNLoss/localization_loss': 0.0052760066,\n"," 'Loss/RPNLoss/objectness_loss': 0.0009137189,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.040058836,\n"," 'learning_rate': 0.0017663168}\n","I0727 19:56:03.168142 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.017866006,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.016003102,\n"," 'Loss/RPNLoss/localization_loss': 0.0052760066,\n"," 'Loss/RPNLoss/objectness_loss': 0.0009137189,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.040058836,\n"," 'learning_rate': 0.0017663168}\n","INFO:tensorflow:Step 22000 per-step time 0.310s\n","I0727 19:56:34.174773 139909792601984 model_lib_v2.py:707] Step 22000 per-step time 0.310s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.020966344,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.017738802,\n"," 'Loss/RPNLoss/localization_loss': 0.005523384,\n"," 'Loss/RPNLoss/objectness_loss': 0.0004452558,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.044673786,\n"," 'learning_rate': 0.0016557729}\n","I0727 19:56:34.175090 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.020966344,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.017738802,\n"," 'Loss/RPNLoss/localization_loss': 0.005523384,\n"," 'Loss/RPNLoss/objectness_loss': 0.0004452558,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.044673786,\n"," 'learning_rate': 0.0016557729}\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0727 19:56:34.278675 139909792601984 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0727 19:56:34.279920 139909792601984 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0727 19:56:34.281919 139909792601984 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0727 19:56:34.282774 139909792601984 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0727 19:56:34.284805 139909792601984 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0727 19:56:34.285778 139909792601984 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0727 19:56:34.288244 139909792601984 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0727 19:56:34.289085 139909792601984 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0727 19:56:34.290651 139909792601984 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0727 19:56:34.291499 139909792601984 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Step 22100 per-step time 0.318s\n","I0727 19:57:06.020100 139909792601984 model_lib_v2.py:707] Step 22100 per-step time 0.318s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.014747738,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.0072803847,\n"," 'Loss/RPNLoss/localization_loss': 0.0016992766,\n"," 'Loss/RPNLoss/objectness_loss': 0.0014910847,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.025218483,\n"," 'learning_rate': 0.0015486514}\n","I0727 19:57:06.020461 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.014747738,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.0072803847,\n"," 'Loss/RPNLoss/localization_loss': 0.0016992766,\n"," 'Loss/RPNLoss/objectness_loss': 0.0014910847,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.025218483,\n"," 'learning_rate': 0.0015486514}\n","INFO:tensorflow:Step 22200 per-step time 0.303s\n","I0727 19:57:36.367420 139909792601984 model_lib_v2.py:707] Step 22200 per-step time 0.303s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.017847756,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.018681467,\n"," 'Loss/RPNLoss/localization_loss': 0.0016864606,\n"," 'Loss/RPNLoss/objectness_loss': 0.0018540325,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.040069714,\n"," 'learning_rate': 0.0014449739}\n","I0727 19:57:36.367731 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.017847756,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.018681467,\n"," 'Loss/RPNLoss/localization_loss': 0.0016864606,\n"," 'Loss/RPNLoss/objectness_loss': 0.0018540325,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.040069714,\n"," 'learning_rate': 0.0014449739}\n","INFO:tensorflow:Step 22300 per-step time 0.309s\n","I0727 19:58:07.241335 139909792601984 model_lib_v2.py:707] Step 22300 per-step time 0.309s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.005866989,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.008939816,\n"," 'Loss/RPNLoss/localization_loss': 0.0020334942,\n"," 'Loss/RPNLoss/objectness_loss': 0.00037968124,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.017219981,\n"," 'learning_rate': 0.0013447559}\n","I0727 19:58:07.241664 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.005866989,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.008939816,\n"," 'Loss/RPNLoss/localization_loss': 0.0020334942,\n"," 'Loss/RPNLoss/objectness_loss': 0.00037968124,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.017219981,\n"," 'learning_rate': 0.0013447559}\n","INFO:tensorflow:Step 22400 per-step time 0.304s\n","I0727 19:58:37.674197 139909792601984 model_lib_v2.py:707] Step 22400 per-step time 0.304s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.019708876,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.011833574,\n"," 'Loss/RPNLoss/localization_loss': 0.010756547,\n"," 'Loss/RPNLoss/objectness_loss': 0.00060432625,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.042903326,\n"," 'learning_rate': 0.0012480199}\n","I0727 19:58:37.674672 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.019708876,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.011833574,\n"," 'Loss/RPNLoss/localization_loss': 0.010756547,\n"," 'Loss/RPNLoss/objectness_loss': 0.00060432625,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.042903326,\n"," 'learning_rate': 0.0012480199}\n","INFO:tensorflow:Step 22500 per-step time 0.305s\n","I0727 19:59:08.214106 139909792601984 model_lib_v2.py:707] Step 22500 per-step time 0.305s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.021660531,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010975823,\n"," 'Loss/RPNLoss/localization_loss': 0.006428801,\n"," 'Loss/RPNLoss/objectness_loss': 0.00030295708,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.039368108,\n"," 'learning_rate': 0.0011547804}\n","I0727 19:59:08.214441 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.021660531,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010975823,\n"," 'Loss/RPNLoss/localization_loss': 0.006428801,\n"," 'Loss/RPNLoss/objectness_loss': 0.00030295708,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.039368108,\n"," 'learning_rate': 0.0011547804}\n","INFO:tensorflow:Step 22600 per-step time 0.303s\n","I0727 19:59:38.553072 139909792601984 model_lib_v2.py:707] Step 22600 per-step time 0.303s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.016815558,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.008870445,\n"," 'Loss/RPNLoss/localization_loss': 0.0010846449,\n"," 'Loss/RPNLoss/objectness_loss': 0.00056905183,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.027339699,\n"," 'learning_rate': 0.0010650586}\n","I0727 19:59:38.553412 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.016815558,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.008870445,\n"," 'Loss/RPNLoss/localization_loss': 0.0010846449,\n"," 'Loss/RPNLoss/objectness_loss': 0.00056905183,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.027339699,\n"," 'learning_rate': 0.0010650586}\n","INFO:tensorflow:Step 22700 per-step time 0.311s\n","I0727 20:00:09.664728 139909792601984 model_lib_v2.py:707] Step 22700 per-step time 0.311s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.011488117,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.0050707287,\n"," 'Loss/RPNLoss/localization_loss': 0.00037092873,\n"," 'Loss/RPNLoss/objectness_loss': 0.0002259936,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.017155768,\n"," 'learning_rate': 0.0009788703}\n","I0727 20:00:09.665102 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.011488117,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.0050707287,\n"," 'Loss/RPNLoss/localization_loss': 0.00037092873,\n"," 'Loss/RPNLoss/objectness_loss': 0.0002259936,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.017155768,\n"," 'learning_rate': 0.0009788703}\n","INFO:tensorflow:Step 22800 per-step time 0.306s\n","I0727 20:00:40.278306 139909792601984 model_lib_v2.py:707] Step 22800 per-step time 0.306s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.011912091,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010059073,\n"," 'Loss/RPNLoss/localization_loss': 0.0015034875,\n"," 'Loss/RPNLoss/objectness_loss': 0.00022288562,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.023697536,\n"," 'learning_rate': 0.00089622854}\n","I0727 20:00:40.278645 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.011912091,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010059073,\n"," 'Loss/RPNLoss/localization_loss': 0.0015034875,\n"," 'Loss/RPNLoss/objectness_loss': 0.00022288562,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.023697536,\n"," 'learning_rate': 0.00089622854}\n","INFO:tensorflow:Step 22900 per-step time 0.304s\n","I0727 20:01:10.633202 139909792601984 model_lib_v2.py:707] Step 22900 per-step time 0.304s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.012799026,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010199686,\n"," 'Loss/RPNLoss/localization_loss': 0.00091815204,\n"," 'Loss/RPNLoss/objectness_loss': 0.00035225885,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.024269124,\n"," 'learning_rate': 0.00081715226}\n","I0727 20:01:10.633572 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.012799026,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010199686,\n"," 'Loss/RPNLoss/localization_loss': 0.00091815204,\n"," 'Loss/RPNLoss/objectness_loss': 0.00035225885,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.024269124,\n"," 'learning_rate': 0.00081715226}\n","INFO:tensorflow:Step 23000 per-step time 0.311s\n","I0727 20:01:41.760677 139909792601984 model_lib_v2.py:707] Step 23000 per-step time 0.311s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0121837,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.008404126,\n"," 'Loss/RPNLoss/localization_loss': 0.00039731263,\n"," 'Loss/RPNLoss/objectness_loss': 0.0001839021,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.021169042,\n"," 'learning_rate': 0.0007416546}\n","I0727 20:01:41.761014 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0121837,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.008404126,\n"," 'Loss/RPNLoss/localization_loss': 0.00039731263,\n"," 'Loss/RPNLoss/objectness_loss': 0.0001839021,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.021169042,\n"," 'learning_rate': 0.0007416546}\n","INFO:tensorflow:Step 23100 per-step time 0.318s\n","I0727 20:02:13.516300 139909792601984 model_lib_v2.py:707] Step 23100 per-step time 0.318s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.013806571,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010750587,\n"," 'Loss/RPNLoss/localization_loss': 0.001446784,\n"," 'Loss/RPNLoss/objectness_loss': 0.0004302423,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.026434185,\n"," 'learning_rate': 0.0006697476}\n","I0727 20:02:13.516643 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.013806571,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010750587,\n"," 'Loss/RPNLoss/localization_loss': 0.001446784,\n"," 'Loss/RPNLoss/objectness_loss': 0.0004302423,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.026434185,\n"," 'learning_rate': 0.0006697476}\n","INFO:tensorflow:Step 23200 per-step time 0.303s\n","I0727 20:02:43.856671 139909792601984 model_lib_v2.py:707] Step 23200 per-step time 0.303s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.01791922,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009488243,\n"," 'Loss/RPNLoss/localization_loss': 0.002242594,\n"," 'Loss/RPNLoss/objectness_loss': 0.000535245,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.0301853,\n"," 'learning_rate': 0.0006014514}\n","I0727 20:02:43.857028 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.01791922,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009488243,\n"," 'Loss/RPNLoss/localization_loss': 0.002242594,\n"," 'Loss/RPNLoss/objectness_loss': 0.000535245,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.0301853,\n"," 'learning_rate': 0.0006014514}\n","INFO:tensorflow:Step 23300 per-step time 0.304s\n","I0727 20:03:14.210499 139909792601984 model_lib_v2.py:707] Step 23300 per-step time 0.304s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.028977439,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.013684563,\n"," 'Loss/RPNLoss/localization_loss': 0.0015120365,\n"," 'Loss/RPNLoss/objectness_loss': 0.0015963796,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.045770418,\n"," 'learning_rate': 0.000536772}\n","I0727 20:03:14.210824 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.028977439,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.013684563,\n"," 'Loss/RPNLoss/localization_loss': 0.0015120365,\n"," 'Loss/RPNLoss/objectness_loss': 0.0015963796,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.045770418,\n"," 'learning_rate': 0.000536772}\n","INFO:tensorflow:Step 23400 per-step time 0.309s\n","I0727 20:03:45.082124 139909792601984 model_lib_v2.py:707] Step 23400 per-step time 0.309s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.023944443,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010097198,\n"," 'Loss/RPNLoss/localization_loss': 0.0013183267,\n"," 'Loss/RPNLoss/objectness_loss': 0.00022954732,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03558952,\n"," 'learning_rate': 0.00047572254}\n","I0727 20:03:45.082487 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.023944443,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010097198,\n"," 'Loss/RPNLoss/localization_loss': 0.0013183267,\n"," 'Loss/RPNLoss/objectness_loss': 0.00022954732,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03558952,\n"," 'learning_rate': 0.00047572254}\n","INFO:tensorflow:Step 23500 per-step time 0.304s\n","I0727 20:04:15.516643 139909792601984 model_lib_v2.py:707] Step 23500 per-step time 0.304s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.03504717,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.011389804,\n"," 'Loss/RPNLoss/localization_loss': 0.012613862,\n"," 'Loss/RPNLoss/objectness_loss': 0.00088209123,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.05993293,\n"," 'learning_rate': 0.0004183185}\n","I0727 20:04:15.516975 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.03504717,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.011389804,\n"," 'Loss/RPNLoss/localization_loss': 0.012613862,\n"," 'Loss/RPNLoss/objectness_loss': 0.00088209123,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.05993293,\n"," 'learning_rate': 0.0004183185}\n","INFO:tensorflow:Step 23600 per-step time 0.303s\n","I0727 20:04:45.849125 139909792601984 model_lib_v2.py:707] Step 23600 per-step time 0.303s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.03009113,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.015787018,\n"," 'Loss/RPNLoss/localization_loss': 0.0034122241,\n"," 'Loss/RPNLoss/objectness_loss': 0.0010287851,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.050319158,\n"," 'learning_rate': 0.00036456465}\n","I0727 20:04:45.849462 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.03009113,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.015787018,\n"," 'Loss/RPNLoss/localization_loss': 0.0034122241,\n"," 'Loss/RPNLoss/objectness_loss': 0.0010287851,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.050319158,\n"," 'learning_rate': 0.00036456465}\n","INFO:tensorflow:Step 23700 per-step time 0.309s\n","I0727 20:05:16.786481 139909792601984 model_lib_v2.py:707] Step 23700 per-step time 0.309s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.017863499,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.012997357,\n"," 'Loss/RPNLoss/localization_loss': 0.0039808997,\n"," 'Loss/RPNLoss/objectness_loss': 0.0007590506,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.035600808,\n"," 'learning_rate': 0.0003144765}\n","I0727 20:05:16.786859 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.017863499,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.012997357,\n"," 'Loss/RPNLoss/localization_loss': 0.0039808997,\n"," 'Loss/RPNLoss/objectness_loss': 0.0007590506,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.035600808,\n"," 'learning_rate': 0.0003144765}\n","INFO:tensorflow:Step 23800 per-step time 0.305s\n","I0727 20:05:47.316756 139909792601984 model_lib_v2.py:707] Step 23800 per-step time 0.305s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.023717593,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010034325,\n"," 'Loss/RPNLoss/localization_loss': 0.0027058958,\n"," 'Loss/RPNLoss/objectness_loss': 0.0015981911,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.038056005,\n"," 'learning_rate': 0.00026806234}\n","I0727 20:05:47.317082 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.023717593,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010034325,\n"," 'Loss/RPNLoss/localization_loss': 0.0027058958,\n"," 'Loss/RPNLoss/objectness_loss': 0.0015981911,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.038056005,\n"," 'learning_rate': 0.00026806234}\n","INFO:tensorflow:Step 23900 per-step time 0.303s\n","I0727 20:06:17.656085 139909792601984 model_lib_v2.py:707] Step 23900 per-step time 0.303s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.033769913,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.025989577,\n"," 'Loss/RPNLoss/localization_loss': 0.0012376764,\n"," 'Loss/RPNLoss/objectness_loss': 0.0008307429,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.06182791,\n"," 'learning_rate': 0.00022532581}\n","I0727 20:06:17.656435 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.033769913,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.025989577,\n"," 'Loss/RPNLoss/localization_loss': 0.0012376764,\n"," 'Loss/RPNLoss/objectness_loss': 0.0008307429,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.06182791,\n"," 'learning_rate': 0.00022532581}\n","INFO:tensorflow:Step 24000 per-step time 0.304s\n","I0727 20:06:48.030345 139909792601984 model_lib_v2.py:707] Step 24000 per-step time 0.304s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.039033942,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009710971,\n"," 'Loss/RPNLoss/localization_loss': 0.00654446,\n"," 'Loss/RPNLoss/objectness_loss': 0.00044349328,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.055732865,\n"," 'learning_rate': 0.0001862812}\n","I0727 20:06:48.030701 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.039033942,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009710971,\n"," 'Loss/RPNLoss/localization_loss': 0.00654446,\n"," 'Loss/RPNLoss/objectness_loss': 0.00044349328,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.055732865,\n"," 'learning_rate': 0.0001862812}\n","INFO:tensorflow:Step 24100 per-step time 0.330s\n","I0727 20:07:21.010301 139909792601984 model_lib_v2.py:707] Step 24100 per-step time 0.330s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.013425117,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.01268816,\n"," 'Loss/RPNLoss/localization_loss': 0.0028076526,\n"," 'Loss/RPNLoss/objectness_loss': 0.0017827929,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.030703723,\n"," 'learning_rate': 0.00015093207}\n","I0727 20:07:21.010723 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.013425117,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.01268816,\n"," 'Loss/RPNLoss/localization_loss': 0.0028076526,\n"," 'Loss/RPNLoss/objectness_loss': 0.0017827929,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.030703723,\n"," 'learning_rate': 0.00015093207}\n","INFO:tensorflow:Step 24200 per-step time 0.303s\n","I0727 20:07:51.329079 139909792601984 model_lib_v2.py:707] Step 24200 per-step time 0.303s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.018968806,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009729327,\n"," 'Loss/RPNLoss/localization_loss': 0.0016637703,\n"," 'Loss/RPNLoss/objectness_loss': 0.00047766813,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03083957,\n"," 'learning_rate': 0.00011928677}\n","I0727 20:07:51.329412 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.018968806,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009729327,\n"," 'Loss/RPNLoss/localization_loss': 0.0016637703,\n"," 'Loss/RPNLoss/objectness_loss': 0.00047766813,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03083957,\n"," 'learning_rate': 0.00011928677}\n","INFO:tensorflow:Step 24300 per-step time 0.304s\n","I0727 20:08:21.767622 139909792601984 model_lib_v2.py:707] Step 24300 per-step time 0.304s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.019726576,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.00756564,\n"," 'Loss/RPNLoss/localization_loss': 0.0034071247,\n"," 'Loss/RPNLoss/objectness_loss': 0.00059790706,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.031297248,\n"," 'learning_rate': 9.135008e-05}\n","I0727 20:08:21.767939 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.019726576,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.00756564,\n"," 'Loss/RPNLoss/localization_loss': 0.0034071247,\n"," 'Loss/RPNLoss/objectness_loss': 0.00059790706,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.031297248,\n"," 'learning_rate': 9.135008e-05}\n","INFO:tensorflow:Step 24400 per-step time 0.310s\n","I0727 20:08:52.801982 139909792601984 model_lib_v2.py:707] Step 24400 per-step time 0.310s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.008234275,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010561748,\n"," 'Loss/RPNLoss/localization_loss': 0.0014483909,\n"," 'Loss/RPNLoss/objectness_loss': 0.0007606007,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.021005014,\n"," 'learning_rate': 6.712794e-05}\n","I0727 20:08:52.802304 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.008234275,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.010561748,\n"," 'Loss/RPNLoss/localization_loss': 0.0014483909,\n"," 'Loss/RPNLoss/objectness_loss': 0.0007606007,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.021005014,\n"," 'learning_rate': 6.712794e-05}\n","INFO:tensorflow:Step 24500 per-step time 0.303s\n","I0727 20:09:23.124783 139909792601984 model_lib_v2.py:707] Step 24500 per-step time 0.303s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.031118171,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.005848204,\n"," 'Loss/RPNLoss/localization_loss': 0.0004484756,\n"," 'Loss/RPNLoss/objectness_loss': 6.191777e-05,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03747677,\n"," 'learning_rate': 4.6623943e-05}\n","I0727 20:09:23.125105 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.031118171,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.005848204,\n"," 'Loss/RPNLoss/localization_loss': 0.0004484756,\n"," 'Loss/RPNLoss/objectness_loss': 6.191777e-05,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03747677,\n"," 'learning_rate': 4.6623943e-05}\n","INFO:tensorflow:Step 24600 per-step time 0.306s\n","I0727 20:09:53.694177 139909792601984 model_lib_v2.py:707] Step 24600 per-step time 0.306s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.006313826,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009728682,\n"," 'Loss/RPNLoss/localization_loss': 0.0014692238,\n"," 'Loss/RPNLoss/objectness_loss': 0.0006202332,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.018131964,\n"," 'learning_rate': 2.9844045e-05}\n","I0727 20:09:53.694517 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.006313826,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009728682,\n"," 'Loss/RPNLoss/localization_loss': 0.0014692238,\n"," 'Loss/RPNLoss/objectness_loss': 0.0006202332,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.018131964,\n"," 'learning_rate': 2.9844045e-05}\n","INFO:tensorflow:Step 24700 per-step time 0.304s\n","I0727 20:10:24.127076 139909792601984 model_lib_v2.py:707] Step 24700 per-step time 0.304s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.016837578,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.014537529,\n"," 'Loss/RPNLoss/localization_loss': 0.003357203,\n"," 'Loss/RPNLoss/objectness_loss': 0.00091339945,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03564571,\n"," 'learning_rate': 1.6789436e-05}\n","I0727 20:10:24.127427 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.016837578,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.014537529,\n"," 'Loss/RPNLoss/localization_loss': 0.003357203,\n"," 'Loss/RPNLoss/objectness_loss': 0.00091339945,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.03564571,\n"," 'learning_rate': 1.6789436e-05}\n","INFO:tensorflow:Step 24800 per-step time 0.312s\n","I0727 20:10:55.306787 139909792601984 model_lib_v2.py:707] Step 24800 per-step time 0.312s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.025740996,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.0119038625,\n"," 'Loss/RPNLoss/localization_loss': 0.001388707,\n"," 'Loss/RPNLoss/objectness_loss': 0.00030085637,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.039334424,\n"," 'learning_rate': 7.4625013e-06}\n","I0727 20:10:55.307110 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.025740996,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.0119038625,\n"," 'Loss/RPNLoss/localization_loss': 0.001388707,\n"," 'Loss/RPNLoss/objectness_loss': 0.00030085637,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.039334424,\n"," 'learning_rate': 7.4625013e-06}\n","INFO:tensorflow:Step 24900 per-step time 0.303s\n","I0727 20:11:25.640005 139909792601984 model_lib_v2.py:707] Step 24900 per-step time 0.303s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.021965452,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.014038498,\n"," 'Loss/RPNLoss/localization_loss': 0.0059110774,\n"," 'Loss/RPNLoss/objectness_loss': 0.003056385,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.04497141,\n"," 'learning_rate': 1.8656253e-06}\n","I0727 20:11:25.640386 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.021965452,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.014038498,\n"," 'Loss/RPNLoss/localization_loss': 0.0059110774,\n"," 'Loss/RPNLoss/objectness_loss': 0.003056385,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.04497141,\n"," 'learning_rate': 1.8656253e-06}\n","INFO:tensorflow:Step 25000 per-step time 0.303s\n","I0727 20:11:55.901137 139909792601984 model_lib_v2.py:707] Step 25000 per-step time 0.303s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.03018853,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009947116,\n"," 'Loss/RPNLoss/localization_loss': 0.0011984562,\n"," 'Loss/RPNLoss/objectness_loss': 0.00039354147,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.04172764,\n"," 'learning_rate': 0.0}\n","I0727 20:11:55.901517 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.03018853,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009947116,\n"," 'Loss/RPNLoss/localization_loss': 0.0011984562,\n"," 'Loss/RPNLoss/objectness_loss': 0.00039354147,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.04172764,\n"," 'learning_rate': 0.0}\n","INFO:tensorflow:Step 25100 per-step time 0.329s\n","I0727 20:12:28.787501 139909792601984 model_lib_v2.py:707] Step 25100 per-step time 0.329s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0045019346,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009524167,\n"," 'Loss/RPNLoss/localization_loss': 0.00073299825,\n"," 'Loss/RPNLoss/objectness_loss': 0.00012722335,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.014886323,\n"," 'learning_rate': 0.0}\n","I0727 20:12:28.787828 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0045019346,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009524167,\n"," 'Loss/RPNLoss/localization_loss': 0.00073299825,\n"," 'Loss/RPNLoss/objectness_loss': 0.00012722335,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.014886323,\n"," 'learning_rate': 0.0}\n","INFO:tensorflow:Step 25200 per-step time 0.305s\n","I0727 20:12:59.254905 139909792601984 model_lib_v2.py:707] Step 25200 per-step time 0.305s\n","INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.016186258,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009314555,\n"," 'Loss/RPNLoss/localization_loss': 0.0033073733,\n"," 'Loss/RPNLoss/objectness_loss': 0.00026095525,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.02906914,\n"," 'learning_rate': 0.0}\n","I0727 20:12:59.255223 139909792601984 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.016186258,\n"," 'Loss/BoxClassifierLoss/localization_loss': 0.009314555,\n"," 'Loss/RPNLoss/localization_loss': 0.0033073733,\n"," 'Loss/RPNLoss/objectness_loss': 0.00026095525,\n"," 'Loss/regularization_loss': 0.0,\n"," 'Loss/total_loss': 0.02906914,\n"," 'learning_rate': 0.0}\n","^C\n"]}]},{"cell_type":"markdown","metadata":{"id":"PCmWC2Ae8DjW"},"source":["Congratulations! You have finished model training!"]},{"cell_type":"markdown","source":["Here we're going yo run the code through a llop that waits for checkpoints to evaluate. Once the evaluation finishes, you're going to see the message:\n","\n","`INFO:tensorflow:Waiting for new checkpoint at /content/training/`\n","\n","Then you can stop the cell\n"],"metadata":{"id":"p3J9qwcLQy8m"}},{"cell_type":"code","source":["!python /content/gdrive/MyDrive/TensorFlow/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_config_path} \\\n","    --model_dir={model_dir} \\\n","    --checkpoint_dir={model_dir}           ##This is passed to run ONLY EVALUATION"],"metadata":{"id":"UhmRTbnYQVhc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658953122811,"user_tz":-60,"elapsed":320811,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"26e3c962-5d92-4aca-c693-fdf48ce9358a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0727 20:13:26.451916 139734829680512 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n","I0727 20:13:26.452160 139734829680512 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0727 20:13:26.452245 139734829680512 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0727 20:13:26.452326 139734829680512 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0727 20:13:26.452457 139734829680512 model_lib_v2.py:1110] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","2022-07-27 20:13:27.183913: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/test.record']\n","I0727 20:13:27.211031 139734829680512 dataset_builder.py:162] Reading unweighted datasets: ['/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/test.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/test.record']\n","I0727 20:13:27.211546 139734829680512 dataset_builder.py:79] Reading record datasets for input file: ['/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/test.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0727 20:13:27.211703 139734829680512 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0727 20:13:27.211784 139734829680512 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0727 20:13:27.214054 139734829680512 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0727 20:13:27.235894 139734829680512 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0727 20:13:31.132355 139734829680512 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0727 20:13:32.490391 139734829680512 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/TensorFlow/workspace/model3/exported-models\n","I0727 20:13:34.981089 139734829680512 checkpoint_utils.py:136] Waiting for new checkpoint at /content/gdrive/MyDrive/TensorFlow/workspace/model3/exported-models\n","INFO:tensorflow:Found new checkpoint at /content/gdrive/MyDrive/TensorFlow/workspace/model3/exported-models/ckpt-28\n","I0727 20:13:34.984316 139734829680512 checkpoint_utils.py:145] Found new checkpoint at /content/gdrive/MyDrive/TensorFlow/workspace/model3/exported-models/ckpt-28\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0727 20:13:42.046772 139734829680512 convolutional_keras_box_predictor.py:153] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use ref() instead.\n","W0727 20:13:50.480121 139734829680512 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use ref() instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W0727 20:13:55.683716 139734829680512 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0727 20:14:18.374888 139734829680512 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Finished eval step 0\n","I0727 20:14:18.403223 139734829680512 model_lib_v2.py:966] Finished eval step 0\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0727 20:14:18.565810 139734829680512 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Performing evaluation on 80 images.\n","I0727 20:14:57.205086 139734829680512 coco_evaluation.py:293] Performing evaluation on 80 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0727 20:14:57.205731 139734829680512 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.01s)\n","I0727 20:14:57.213059 139734829680512 coco_tools.py:138] DONE (t=0.01s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.88s).\n","Accumulating evaluation results...\n","DONE (t=0.13s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.592\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.279\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.189\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.117\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.351\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.574\n","INFO:tensorflow:Eval metrics at step 25000\n","I0727 20:14:58.241715 139734829680512 model_lib_v2.py:1015] Eval metrics at step 25000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.308872\n","I0727 20:14:58.243828 139734829680512 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.308872\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.592197\n","I0727 20:14:58.245154 139734829680512 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.592197\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.279274\n","I0727 20:14:58.246433 139734829680512 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.279274\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.025000\n","I0727 20:14:58.262727 139734829680512 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.025000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.188555\n","I0727 20:14:58.264713 139734829680512 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.188555\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.461262\n","I0727 20:14:58.266553 139734829680512 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.461262\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.116815\n","I0727 20:14:58.268252 139734829680512 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.116815\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.351263\n","I0727 20:14:58.269996 139734829680512 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.351263\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.437676\n","I0727 20:14:58.271662 139734829680512 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.437676\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.100000\n","I0727 20:14:58.273307 139734829680512 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.100000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.333698\n","I0727 20:14:58.275128 139734829680512 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.333698\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.573733\n","I0727 20:14:58.276546 139734829680512 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.573733\n","INFO:tensorflow:\t+ Loss/RPNLoss/localization_loss: 0.172348\n","I0727 20:14:58.277538 139734829680512 model_lib_v2.py:1018] \t+ Loss/RPNLoss/localization_loss: 0.172348\n","INFO:tensorflow:\t+ Loss/RPNLoss/objectness_loss: 0.230158\n","I0727 20:14:58.278693 139734829680512 model_lib_v2.py:1018] \t+ Loss/RPNLoss/objectness_loss: 0.230158\n","INFO:tensorflow:\t+ Loss/BoxClassifierLoss/localization_loss: 0.133501\n","I0727 20:14:58.280003 139734829680512 model_lib_v2.py:1018] \t+ Loss/BoxClassifierLoss/localization_loss: 0.133501\n","INFO:tensorflow:\t+ Loss/BoxClassifierLoss/classification_loss: 0.263314\n","I0727 20:14:58.281152 139734829680512 model_lib_v2.py:1018] \t+ Loss/BoxClassifierLoss/classification_loss: 0.263314\n","INFO:tensorflow:\t+ Loss/regularization_loss: 0.000000\n","I0727 20:14:58.282195 139734829680512 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.000000\n","INFO:tensorflow:\t+ Loss/total_loss: 0.799320\n","I0727 20:14:58.283245 139734829680512 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.799320\n","INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/TensorFlow/workspace/model3/exported-models\n","I0727 20:18:35.043052 139734829680512 checkpoint_utils.py:136] Waiting for new checkpoint at /content/gdrive/MyDrive/TensorFlow/workspace/model3/exported-models\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/TensorFlow/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/gdrive/MyDrive/TensorFlow/models/research/object_detection/model_main_tf2.py\", line 89, in main\n","    wait_interval=300, timeout=FLAGS.eval_timeout)\n","  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1136, in eval_continuously\n","    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 195, in checkpoints_iterator\n","    checkpoint_dir, checkpoint_path, timeout=timeout)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 143, in wait_for_new_checkpoint\n","    time.sleep(seconds_to_sleep)\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["%cd '/content/gdrive/My Drive/TensorFlow/workspace/model3'\n","%load_ext tensorboard\n","%tensorboard --logdir=exported-models/eval\n","#%tensorboard --logdir=models/my_rcnn\n","#%tensorboard --logdir '/content/drive/MyDrive/object_detection/scripts'\n"],"metadata":{"id":"-04i56CTvdIQ","colab":{"base_uri":"https://localhost:8080/","height":872},"executionInfo":{"status":"ok","timestamp":1658953133631,"user_tz":-60,"elapsed":3840,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"504b921a-c53b-4b07-f22d-40166777971c"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zDSirOAQ-0sy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658953217741,"user_tz":-60,"elapsed":41400,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"1e20ba05-d7ab-42a1-d679-95c7bb5a0107"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-07-27 20:19:40.589125: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","W0727 20:19:42.070126 140302542735232 deprecation.py:628] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0727 20:19:46.373084 140302542735232 convolutional_keras_box_predictor.py:153] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use ref() instead.\n","W0727 20:19:53.312189 140302542735232 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use ref() instead.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x7f9a3067c1d0>, because it is not built.\n","W0727 20:19:58.923077 140302542735232 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x7f9a3067c1d0>, because it is not built.\n","W0727 20:20:10.666844 140302542735232 save.py:238] Found untraced functions such as FirstStageBoxPredictor_layer_call_fn, FirstStageBoxPredictor_layer_call_and_return_conditional_losses, mask_rcnn_keras_box_predictor_layer_call_fn, mask_rcnn_keras_box_predictor_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op while saving (showing 5 of 84). These functions will not be directly callable after loading.\n","INFO:tensorflow:Assets written to: ./exported-models/my_model/saved_model/assets\n","I0727 20:20:15.290983 140302542735232 builder_impl.py:780] Assets written to: ./exported-models/my_model/saved_model/assets\n","INFO:tensorflow:Writing pipeline config file to ./exported-models/my_model/pipeline.config\n","I0727 20:20:15.683394 140302542735232 config_util.py:254] Writing pipeline config file to ./exported-models/my_model/pipeline.config\n"]}],"source":["#Step 16- Export the Trained Model.\n","#run the cell to start model training \n","!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./models/my_fat_cnnresnet50/pipeline.config --trained_checkpoint_dir ./exported-models/ --output_directory ./exported-models/my_model\n","#python exporter_main_v2.py --input_type image_tensor --pipeline_config_path models/my_mobilenet_ssd_v2_keras/pipeline.config --trained_checkpoint_dir models/my_mobilenet_ssd_v2_keras/ --output_directory exported-models/my_model"]},{"cell_type":"markdown","metadata":{"id":"tAQWLOON4dZt"},"source":["We have finished training and exporting our model. It's time to test our model!"]},{"cell_type":"code","source":["%cd /content/gdrive/My Drive/TensorFlow/scripts/\n","!python confusion_matrix_tf2.py --input_tfrecord_path=/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/test.record --output_path=/content/gdrive/MyDrive/TensorFlow/workspace/model3/confuse/confusion_matrix.csv --inference_graph=/content/gdrive/MyDrive/TensorFlow/workspace/model3/exported-models/my_model/saved_model/ --class_labels=/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/label_map.pbtxt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HpZBSYZ7VJF8","executionInfo":{"status":"ok","timestamp":1658953970720,"user_tz":-60,"elapsed":22298,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"aaf7e83e-003c-40ba-f85c-08b3c81178f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/TensorFlow/scripts\n","/content/gdrive/MyDrive/TensorFlow/workspace/model3/annotations/test.record\n","Loading model...\n","2022-07-27 20:32:32.305084: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","Evaluating model...\n","| |                                  #                | 83 Elapsed Time: 0:00:06\n","Processed 84 images\n","Saving confusion matrix...\n","\n","Confusion Matrix:\n","[[127.   1. 124.]\n"," [  1.  51.  48.]\n"," [ 12.   0.   0.]] \n","\n","  category  ...  recall_@0.5IOU\n","0  illegal  ...        0.503968\n","1    legal  ...        0.510000\n","\n","[2 rows x 3 columns]\n","Done!\n"]}]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/hugozanini/object-detection/master/inferenceutils.py\n","from inferenceutils import *"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ZD5n_DbVJCZ","executionInfo":{"status":"ok","timestamp":1658953976280,"user_tz":-60,"elapsed":1005,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"7f638bcc-56a0-4716-df5c-d065f1f40bff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-07-27 20:32:55--  https://raw.githubusercontent.com/hugozanini/object-detection/master/inferenceutils.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2219 (2.2K) [text/plain]\n","Saving to: ‘inferenceutils.py.1’\n","\n","\rinferenceutils.py.1   0%[                    ]       0  --.-KB/s               \rinferenceutils.py.1 100%[===================>]   2.17K  --.-KB/s    in 0.001s  \n","\n","2022-07-27 20:32:55 (2.49 MB/s) - ‘inferenceutils.py.1’ saved [2219/2219]\n","\n"]}]},{"cell_type":"code","source":["category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)\n","tf.keras.backend.clear_session()\n","model = tf.saved_model.load(f'/content/gdrive/MyDrive/TensorFlow/workspace/model3/exported-models/my_model/saved_model')"],"metadata":{"id":"g_VIs-GJVI3I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","test = pd.read_csv('/content/gdrive/MyDrive/TensorFlow/workspace/model3/images/test_labels.csv')\n","#Getting 3 random images to test\n","images = list(test.sample(n=10)['filename'])"],"metadata":{"id":"xUy_AKjjVIed"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KAXeo2IHVXUB","executionInfo":{"status":"ok","timestamp":1658953993808,"user_tz":-60,"elapsed":13,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"2b71cd6f-521a-4e21-950f-53151c36fb4c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['-70_94__-3_43_2021-01-17.jpg',\n"," '-53_78__0_28_2019-09-24.jpg',\n"," '-53_03__0_05_2018-10-14_aug1.jpg',\n"," '-53_42__-0_09_2019-09-24_aug2.jpg',\n"," '-63_19__3_66_2019-09-21.jpg',\n"," '-63_4__-9_92_2018-07-25_aug1.jpg',\n"," '-52_35__0_74_2019-09-24_aug1.jpg',\n"," '-63_44__-10_04_2018-07-25.jpg',\n"," '-70_98__-3_55_2021-01-17_aug2.jpg',\n"," '-71_48__-3_52_2021-01-17.jpg']"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["for image_name in images:\n","  \n","  image_np = load_image_into_numpy_array('/content/gdrive/MyDrive/TensorFlow/workspace/model3/images/test/' + image_name)\n","  output_dict = run_inference_for_single_image(model, image_np)\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np,\n","      output_dict['detection_boxes'],\n","      output_dict['detection_classes'],\n","      output_dict['detection_scores'],\n","      category_index,\n","      instance_masks=output_dict.get('detection_masks_reframed', None),\n","      use_normalized_coordinates=True,\n","      line_thickness=5)\n","  display(Image.fromarray(image_np))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"AXmTLy8mVe0S","executionInfo":{"status":"ok","timestamp":1658954026077,"user_tz":-60,"elapsed":26420,"user":{"displayName":"Leo Wong","userId":"03667874777591711323"}},"outputId":"e0fbf1c2-c14e-4dd8-e916-296fa50c4f60"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"True","provenance":[{"file_id":"1M3eCsEoA02xM2m84dCqHWy_qlDdHlIiC","timestamp":1656510034652},{"file_id":"https://github.com/Nkap23/TensorFlow_with_Colab_tutorial/blob/master/TensorFlow_with_Colab_tutorial.ipynb","timestamp":1656370951017}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}